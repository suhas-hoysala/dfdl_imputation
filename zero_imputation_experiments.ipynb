{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 01:31:56.844559: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 01:31:57.658324: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 01:31:59.003925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 01:32:12.663712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_experiments import run_simulation\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from IPython.display import display, clear_output\n",
    "from consolidated_runs import run_simulations\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'baselines'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'metrics'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'prev_methods', 'clustering'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'prev_methods', 'reconstruct_grn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    outputs = []\n",
    "    ret_df = None\n",
    "    for dataset in [3]:\n",
    "        if not os.path.exists(f\"./zero_imputation_experiments/DS{dataset}/\"):\n",
    "            os.makedirs(f\"./zero_imputation_experiments/DS{dataset}/\")\n",
    "        # Run for first iteration to prevent race condition\n",
    "        res = run_simulation(\n",
    "            dataset=dataset,\n",
    "            sergio=True,\n",
    "            saucie=True, \n",
    "            scScope=True, \n",
    "            deepImpute=True, \n",
    "            magic=True, \n",
    "            genie=True,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=True,\n",
    "            precision_recall_k=False,\n",
    "            run_with_regs=False,\n",
    "            iteration=0\n",
    "        )\n",
    "        clear_output()\n",
    "        if ret_df is None:\n",
    "            ret_df = pd.DataFrame(columns=res.keys())\n",
    "        new_df = pd.DataFrame([res], columns=res.keys())\n",
    "        ret_df = pd.concat([ret_df, new_df], ignore_index=True)\n",
    "        #write to temp file\n",
    "        ret_df.to_csv(\"zero_imputation_experiments/imputation_results.csv\", index=False)\n",
    "        with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "            futures = []\n",
    "            for i in range(1, 30):\n",
    "                futures.append(executor.submit(run_simulation, \n",
    "                        dataset=dataset,\n",
    "                        sergio=(i == 0),\n",
    "                        saucie=True, \n",
    "                        scScope=True, \n",
    "                        deepImpute=True, \n",
    "                        magic=True, \n",
    "                        genie=True,\n",
    "                        arboreto=False,\n",
    "                        pearson=False,\n",
    "                        roc=True,\n",
    "                        precision_recall_k=False,\n",
    "                        run_with_regs=False,\n",
    "                        iteration=i\n",
    "                    ))\n",
    "                clear_output()\n",
    "            for future in tqdm(futures):\n",
    "                res = future.result()\n",
    "                clear_output(wait=True)\n",
    "                if ret_df is None:\n",
    "                    ret_df = pd.DataFrame(columns=res.keys())\n",
    "                new_df = pd.DataFrame([res], columns=res.keys())\n",
    "                ret_df = pd.concat([ret_df, new_df], ignore_index=True)\n",
    "                #write to temp file\n",
    "                ret_df.to_csv(\"zero_imputation_experiments/imputation_results.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Running SERGIO on DS3\n",
      "---> Running SAUCIE on DS3\n",
      "loading data\n",
      "reset graph\n",
      "Initialize saucie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:152: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h1 = tf.layers.dense(self.x, self.layers[0], activation=lrelu, name='encoder_0')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:154: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h2 = tf.layers.dense(h1, self.layers[1], activation=tf.nn.sigmoid, name='encoder_1')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:156: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h3 = tf.layers.dense(h2, self.layers[2], activation=lrelu, name='encoder_2')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:158: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.embedded = tf.layers.dense(h3, self.layers[3], activation=tf.identity, name='embedding')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:161: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h5 = tf.layers.dense(self.embedded, self.layers[2], activation=lrelu, name='decoder_0')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:163: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h6 = tf.layers.dense(h5, self.layers[1], activation=lrelu, name='decoder_1')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:165: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  h7 = tf.layers.dense(h6, self.layers[0], activation=lrelu, name='decoder_2')\n",
      "/scratch/ab9738/dfdl_imputation/baselines/SAUCIE/SAUCIE/model.py:169: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.reconstructed = tf.layers.dense(h7, self.input_dim, activation=tf.identity, name='recon')\n",
      "2024-09-09 02:53:16.064730: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-09 02:53:16.175656: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saucie\n",
      "Train saucie\n",
      "---> Running scScope on DS3 \n",
      "Building Computational Graph on GPU-0\n",
      "WARNING:tensorflow:From /scratch/ab9738/dfdl_imputation/baselines/scScope/scscope/scscope/ops.py:43: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 02:53:32.282931: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finisheded epoch: 100\n",
      "Current reconstruction error is: 0.32588303183604234\n",
      "Finisheded epoch: 200\n",
      "Current reconstruction error is: 0.30992707779149564\n",
      "Finisheded epoch: 300\n",
      "Current reconstruction error is: 0.3002605436454365\n",
      "Finisheded epoch: 400\n",
      "Current reconstruction error is: 0.2959674696915626\n",
      "Finisheded epoch: 500\n",
      "Current reconstruction error is: 0.2939330786506229\n",
      "Finisheded epoch: 600\n",
      "Current reconstruction error is: 0.29293061878116616\n",
      "Finisheded epoch: 700\n",
      "Current reconstruction error is: 0.29230642822609393\n",
      "Finisheded epoch: 800\n",
      "Current reconstruction error is: 0.2919622645163149\n",
      "Finisheded epoch: 900\n",
      "Current reconstruction error is: 0.29165815418648294\n",
      "Finisheded epoch: 1000\n",
      "Current reconstruction error is: 0.2914686136506491\n",
      "Finish training 2700 samples after 1000 epochs. The total training time is 104.29334592819214 seconds.\n",
      "---> Running DeepImpute on DS3 \n",
      "Using all the cores (48)\n",
      "Input dataset is 2700 cells (rows) and 1200 genes (columns)\n",
      "First 3 rows and columns:\n",
      "   0  1  2\n",
      "0  0  0  0\n",
      "1  0  0  0\n",
      "2  0  0  0\n",
      "1024 genes selected for imputation\n",
      "Net 0: 547 predictors, 512 targets\n",
      "Net 1: 553 predictors, 512 targets\n",
      "Normalization\n",
      "Building network\n",
      "[{'type': 'dense', 'neurons': 256, 'activation': 'relu'}, {'type': 'dropout', 'rate': 0.2}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 2700 cells\n",
      "Train on 2565 samples, validate on 135 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 02:55:18.109303: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-09-09 02:55:18.166777: W tensorflow/c/c_api.cc:304] Operation '{name:'training/Adam/dense_2/bias/m/Assign' id:1173 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_2/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_2/bias/m, training/Adam/dense_2/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565/2565 [==============================] - 0s 114us/sample - loss: 0.0977 - dense_2_loss: 0.0621 - dense_3_loss: 0.0364 - val_loss: 0.0935 - val_dense_2_loss: 0.0659 - val_dense_3_loss: 0.0363\n",
      "Epoch 2/500\n",
      "2048/2565 [======================>.......] - ETA: 0s - loss: 0.0837 - dense_2_loss: 0.0541 - dense_3_loss: 0.0296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2024-09-09 02:55:18.510719: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_1/AddN' id:900 op device:{requested: '', assigned: ''} def:{{{node loss_1/AddN}} = AddN[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul, loss_1/mul_1)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565/2565 [==============================] - 0s 55us/sample - loss: 0.0820 - dense_2_loss: 0.0532 - dense_3_loss: 0.0291 - val_loss: 0.0749 - val_dense_2_loss: 0.0461 - val_dense_3_loss: 0.0245\n",
      "Epoch 3/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0631 - dense_2_loss: 0.0416 - dense_3_loss: 0.0210 - val_loss: 0.0529 - val_dense_2_loss: 0.0336 - val_dense_3_loss: 0.0168\n",
      "Epoch 4/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0438 - dense_2_loss: 0.0294 - dense_3_loss: 0.0142 - val_loss: 0.0345 - val_dense_2_loss: 0.0259 - val_dense_3_loss: 0.0109\n",
      "Epoch 5/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0308 - dense_2_loss: 0.0201 - dense_3_loss: 0.0105 - val_loss: 0.0256 - val_dense_2_loss: 0.0184 - val_dense_3_loss: 0.0084\n",
      "Epoch 6/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0255 - dense_2_loss: 0.0168 - dense_3_loss: 0.0091 - val_loss: 0.0229 - val_dense_2_loss: 0.0187 - val_dense_3_loss: 0.0071\n",
      "Epoch 7/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0233 - dense_2_loss: 0.0149 - dense_3_loss: 0.0084 - val_loss: 0.0218 - val_dense_2_loss: 0.0110 - val_dense_3_loss: 0.0074\n",
      "Epoch 8/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0219 - dense_2_loss: 0.0137 - dense_3_loss: 0.0080 - val_loss: 0.0209 - val_dense_2_loss: 0.0145 - val_dense_3_loss: 0.0082\n",
      "Epoch 9/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0206 - dense_2_loss: 0.0131 - dense_3_loss: 0.0075 - val_loss: 0.0200 - val_dense_2_loss: 0.0107 - val_dense_3_loss: 0.0069\n",
      "Epoch 10/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0195 - dense_2_loss: 0.0121 - dense_3_loss: 0.0072 - val_loss: 0.0194 - val_dense_2_loss: 0.0128 - val_dense_3_loss: 0.0080\n",
      "Epoch 11/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0185 - dense_2_loss: 0.0117 - dense_3_loss: 0.0068 - val_loss: 0.0187 - val_dense_2_loss: 0.0117 - val_dense_3_loss: 0.0069\n",
      "Epoch 12/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0178 - dense_2_loss: 0.0111 - dense_3_loss: 0.0067 - val_loss: 0.0181 - val_dense_2_loss: 0.0108 - val_dense_3_loss: 0.0062\n",
      "Epoch 13/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0171 - dense_2_loss: 0.0105 - dense_3_loss: 0.0065 - val_loss: 0.0177 - val_dense_2_loss: 0.0112 - val_dense_3_loss: 0.0055\n",
      "Epoch 14/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0165 - dense_2_loss: 0.0101 - dense_3_loss: 0.0062 - val_loss: 0.0172 - val_dense_2_loss: 0.0108 - val_dense_3_loss: 0.0055\n",
      "Epoch 15/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0161 - dense_2_loss: 0.0099 - dense_3_loss: 0.0062 - val_loss: 0.0169 - val_dense_2_loss: 0.0113 - val_dense_3_loss: 0.0064\n",
      "Epoch 16/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0156 - dense_2_loss: 0.0098 - dense_3_loss: 0.0062 - val_loss: 0.0165 - val_dense_2_loss: 0.0125 - val_dense_3_loss: 0.0079\n",
      "Epoch 17/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0152 - dense_2_loss: 0.0092 - dense_3_loss: 0.0059 - val_loss: 0.0162 - val_dense_2_loss: 0.0097 - val_dense_3_loss: 0.0064\n",
      "Epoch 18/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0150 - dense_2_loss: 0.0092 - dense_3_loss: 0.0059 - val_loss: 0.0160 - val_dense_2_loss: 0.0103 - val_dense_3_loss: 0.0059\n",
      "Epoch 19/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0145 - dense_2_loss: 0.0087 - dense_3_loss: 0.0058 - val_loss: 0.0157 - val_dense_2_loss: 0.0084 - val_dense_3_loss: 0.0052\n",
      "Epoch 20/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0143 - dense_2_loss: 0.0085 - dense_3_loss: 0.0057 - val_loss: 0.0156 - val_dense_2_loss: 0.0086 - val_dense_3_loss: 0.0051\n",
      "Epoch 21/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0142 - dense_2_loss: 0.0085 - dense_3_loss: 0.0057 - val_loss: 0.0154 - val_dense_2_loss: 0.0101 - val_dense_3_loss: 0.0063\n",
      "Epoch 22/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0139 - dense_2_loss: 0.0083 - dense_3_loss: 0.0056 - val_loss: 0.0153 - val_dense_2_loss: 0.0084 - val_dense_3_loss: 0.0056\n",
      "Epoch 23/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0137 - dense_2_loss: 0.0081 - dense_3_loss: 0.0055 - val_loss: 0.0151 - val_dense_2_loss: 0.0092 - val_dense_3_loss: 0.0066\n",
      "Epoch 24/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0136 - dense_2_loss: 0.0080 - dense_3_loss: 0.0055 - val_loss: 0.0150 - val_dense_2_loss: 0.0086 - val_dense_3_loss: 0.0064\n",
      "Epoch 25/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0134 - dense_2_loss: 0.0078 - dense_3_loss: 0.0055 - val_loss: 0.0150 - val_dense_2_loss: 0.0092 - val_dense_3_loss: 0.0063\n",
      "Epoch 26/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0133 - dense_2_loss: 0.0078 - dense_3_loss: 0.0054 - val_loss: 0.0148 - val_dense_2_loss: 0.0083 - val_dense_3_loss: 0.0052\n",
      "Epoch 27/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0131 - dense_2_loss: 0.0077 - dense_3_loss: 0.0053 - val_loss: 0.0148 - val_dense_2_loss: 0.0103 - val_dense_3_loss: 0.0061\n",
      "Epoch 28/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0129 - dense_2_loss: 0.0076 - dense_3_loss: 0.0054 - val_loss: 0.0147 - val_dense_2_loss: 0.0099 - val_dense_3_loss: 0.0067\n",
      "Epoch 29/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0128 - dense_2_loss: 0.0076 - dense_3_loss: 0.0053 - val_loss: 0.0146 - val_dense_2_loss: 0.0090 - val_dense_3_loss: 0.0060\n",
      "Epoch 30/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0126 - dense_2_loss: 0.0074 - dense_3_loss: 0.0052 - val_loss: 0.0146 - val_dense_2_loss: 0.0087 - val_dense_3_loss: 0.0056\n",
      "Epoch 31/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0124 - dense_2_loss: 0.0073 - dense_3_loss: 0.0052 - val_loss: 0.0145 - val_dense_2_loss: 0.0076 - val_dense_3_loss: 0.0051\n",
      "Epoch 32/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0124 - dense_2_loss: 0.0073 - dense_3_loss: 0.0052 - val_loss: 0.0145 - val_dense_2_loss: 0.0095 - val_dense_3_loss: 0.0062\n",
      "Epoch 33/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0123 - dense_2_loss: 0.0074 - dense_3_loss: 0.0051 - val_loss: 0.0144 - val_dense_2_loss: 0.0097 - val_dense_3_loss: 0.0058\n",
      "Epoch 34/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0120 - dense_2_loss: 0.0070 - dense_3_loss: 0.0050 - val_loss: 0.0144 - val_dense_2_loss: 0.0096 - val_dense_3_loss: 0.0060\n",
      "Epoch 35/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0120 - dense_2_loss: 0.0070 - dense_3_loss: 0.0050 - val_loss: 0.0143 - val_dense_2_loss: 0.0081 - val_dense_3_loss: 0.0057\n",
      "Epoch 36/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0118 - dense_2_loss: 0.0068 - dense_3_loss: 0.0049 - val_loss: 0.0143 - val_dense_2_loss: 0.0098 - val_dense_3_loss: 0.0061\n",
      "Epoch 37/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0117 - dense_2_loss: 0.0067 - dense_3_loss: 0.0048 - val_loss: 0.0143 - val_dense_2_loss: 0.0080 - val_dense_3_loss: 0.0050\n",
      "Epoch 38/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0115 - dense_2_loss: 0.0067 - dense_3_loss: 0.0049 - val_loss: 0.0142 - val_dense_2_loss: 0.0091 - val_dense_3_loss: 0.0059\n",
      "Epoch 39/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0115 - dense_2_loss: 0.0067 - dense_3_loss: 0.0048 - val_loss: 0.0142 - val_dense_2_loss: 0.0095 - val_dense_3_loss: 0.0058\n",
      "Epoch 40/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0113 - dense_2_loss: 0.0066 - dense_3_loss: 0.0048 - val_loss: 0.0142 - val_dense_2_loss: 0.0078 - val_dense_3_loss: 0.0055\n",
      "Epoch 41/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0113 - dense_2_loss: 0.0067 - dense_3_loss: 0.0048 - val_loss: 0.0142 - val_dense_2_loss: 0.0081 - val_dense_3_loss: 0.0052\n",
      "Epoch 42/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0112 - dense_2_loss: 0.0065 - dense_3_loss: 0.0047 - val_loss: 0.0142 - val_dense_2_loss: 0.0079 - val_dense_3_loss: 0.0061\n",
      "Epoch 43/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0110 - dense_2_loss: 0.0062 - dense_3_loss: 0.0046 - val_loss: 0.0141 - val_dense_2_loss: 0.0075 - val_dense_3_loss: 0.0055\n",
      "Epoch 44/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0110 - dense_2_loss: 0.0064 - dense_3_loss: 0.0047 - val_loss: 0.0141 - val_dense_2_loss: 0.0076 - val_dense_3_loss: 0.0053\n",
      "Epoch 45/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0109 - dense_2_loss: 0.0063 - dense_3_loss: 0.0046 - val_loss: 0.0141 - val_dense_2_loss: 0.0086 - val_dense_3_loss: 0.0056\n",
      "Epoch 46/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0108 - dense_2_loss: 0.0063 - dense_3_loss: 0.0046 - val_loss: 0.0141 - val_dense_2_loss: 0.0080 - val_dense_3_loss: 0.0050\n",
      "Epoch 47/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0106 - dense_2_loss: 0.0060 - dense_3_loss: 0.0045 - val_loss: 0.0141 - val_dense_2_loss: 0.0085 - val_dense_3_loss: 0.0059\n",
      "Epoch 48/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0106 - dense_2_loss: 0.0061 - dense_3_loss: 0.0045 - val_loss: 0.0141 - val_dense_2_loss: 0.0079 - val_dense_3_loss: 0.0057\n",
      "Epoch 49/500\n",
      "2565/2565 [==============================] - 0s 54us/sample - loss: 0.0104 - dense_2_loss: 0.0061 - dense_3_loss: 0.0045 - val_loss: 0.0141 - val_dense_2_loss: 0.0099 - val_dense_3_loss: 0.0059\n",
      "Epoch 50/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0104 - dense_2_loss: 0.0060 - dense_3_loss: 0.0044 - val_loss: 0.0140 - val_dense_2_loss: 0.0082 - val_dense_3_loss: 0.0061\n",
      "Epoch 51/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0103 - dense_2_loss: 0.0059 - dense_3_loss: 0.0044 - val_loss: 0.0140 - val_dense_2_loss: 0.0084 - val_dense_3_loss: 0.0051\n",
      "Epoch 52/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0102 - dense_2_loss: 0.0059 - dense_3_loss: 0.0043 - val_loss: 0.0140 - val_dense_2_loss: 0.0084 - val_dense_3_loss: 0.0053\n",
      "Epoch 53/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0101 - dense_2_loss: 0.0059 - dense_3_loss: 0.0043 - val_loss: 0.0140 - val_dense_2_loss: 0.0078 - val_dense_3_loss: 0.0056\n",
      "Epoch 54/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0100 - dense_2_loss: 0.0057 - dense_3_loss: 0.0043 - val_loss: 0.0140 - val_dense_2_loss: 0.0087 - val_dense_3_loss: 0.0064\n",
      "Epoch 55/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0100 - dense_2_loss: 0.0057 - dense_3_loss: 0.0043 - val_loss: 0.0140 - val_dense_2_loss: 0.0095 - val_dense_3_loss: 0.0063\n",
      "Epoch 56/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0099 - dense_2_loss: 0.0056 - dense_3_loss: 0.0042 - val_loss: 0.0140 - val_dense_2_loss: 0.0080 - val_dense_3_loss: 0.0054\n",
      "Epoch 57/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0098 - dense_2_loss: 0.0056 - dense_3_loss: 0.0042 - val_loss: 0.0140 - val_dense_2_loss: 0.0082 - val_dense_3_loss: 0.0050\n",
      "Epoch 58/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0098 - dense_2_loss: 0.0057 - dense_3_loss: 0.0042 - val_loss: 0.0140 - val_dense_2_loss: 0.0084 - val_dense_3_loss: 0.0058\n",
      "Epoch 59/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0097 - dense_2_loss: 0.0056 - dense_3_loss: 0.0041 - val_loss: 0.0140 - val_dense_2_loss: 0.0082 - val_dense_3_loss: 0.0057\n",
      "Epoch 60/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0096 - dense_2_loss: 0.0055 - dense_3_loss: 0.0041 - val_loss: 0.0140 - val_dense_2_loss: 0.0085 - val_dense_3_loss: 0.0057\n",
      "Epoch 61/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0096 - dense_2_loss: 0.0055 - dense_3_loss: 0.0041 - val_loss: 0.0140 - val_dense_2_loss: 0.0082 - val_dense_3_loss: 0.0062\n",
      "Epoch 62/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0095 - dense_2_loss: 0.0055 - dense_3_loss: 0.0040 - val_loss: 0.0140 - val_dense_2_loss: 0.0088 - val_dense_3_loss: 0.0059\n",
      "Epoch 63/500\n",
      "2565/2565 [==============================] - 0s 50us/sample - loss: 0.0094 - dense_2_loss: 0.0054 - dense_3_loss: 0.0040 - val_loss: 0.0140 - val_dense_2_loss: 0.0077 - val_dense_3_loss: 0.0053\n",
      "Epoch 64/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0094 - dense_2_loss: 0.0055 - dense_3_loss: 0.0041 - val_loss: 0.0140 - val_dense_2_loss: 0.0073 - val_dense_3_loss: 0.0053\n",
      "Epoch 65/500\n",
      "2565/2565 [==============================] - 0s 51us/sample - loss: 0.0092 - dense_2_loss: 0.0053 - dense_3_loss: 0.0040 - val_loss: 0.0140 - val_dense_2_loss: 0.0091 - val_dense_3_loss: 0.0066\n",
      "Epoch 66/500\n",
      "2565/2565 [==============================] - 0s 52us/sample - loss: 0.0092 - dense_2_loss: 0.0053 - dense_3_loss: 0.0039 - val_loss: 0.0141 - val_dense_2_loss: 0.0077 - val_dense_3_loss: 0.0053\n",
      "Stopped fitting after 66 epochs\n",
      "Saved model to disk in /state/partition1/job-50789262/tmpwvvplwwe\n",
      "WARNING:tensorflow:From /scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/tensorflow/python/ops/init_ops.py:94: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/yz5944/miniconda3/envs/bio-zi/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2024-09-09 02:55:27.532290: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_2/Softplus' id:782 op device:{requested: '', assigned: ''} def:{{{node dense_2/Softplus}} = Softplus[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_2/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-09-09 02:55:27.793586: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_1_1/bias/Assign' id:1381 op device:{requested: '', assigned: ''} def:{{{node dense_1_1/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_1_1/bias, dense_1_1/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-09-09 02:55:27.852868: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_2_1/Softplus' id:1440 op device:{requested: '', assigned: ''} def:{{{node dense_2_1/Softplus}} = Softplus[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_2_1/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling zeros\n",
      "---> Running MAGIC on DS3 \n",
      "./zero_imputation_experiments/DS3/DS6_clean.npy ./zero_imputation_experiments/DS3/DS6_noisy.npy\n",
      "Calculating MAGIC...\n",
      "  Running MAGIC on 2700 cells and 1200 genes.\n",
      "  Calculating graph and diffusion operator...\n",
      "    Calculating PCA...\n",
      "    Calculated PCA in 0.33 seconds.\n",
      "    Calculating KNN search...\n",
      "    Calculated KNN search in 0.26 seconds.\n",
      "    Calculating affinities...\n",
      "    Calculated affinities in 0.25 seconds.\n",
      "  Calculated graph and diffusion operator in 0.85 seconds.\n",
      "  Calculating imputation...\n",
      "  Calculated imputation in 0.32 seconds.\n",
      "Calculated MAGIC in 1.18 seconds.\n",
      "---> Running GENIE3 on Clean Data for DS3 \n",
      "Tree method: RF\n",
      "K: sqrt\n",
      "Number of trees: 100\n",
      "\n",
      "\n",
      "running jobs on 12 threads\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://gr017.hpc.nyu.edu:8888/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Imputation Methods Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dataset in [1,2,3]:\n",
    "    if not os.path.exists(f\"./zero_imputation_experiments/DS{dataset}/\"):\n",
    "        os.makedirs(f\"./zero_imputation_experiments/DS{dataset}/\")\n",
    "    if not os.path.exists(f\"./zero_imputation_experiments/DS{dataset}/DS6_noisy.npy\"):\n",
    "        res = run_simulation(\n",
    "            dataset=dataset,\n",
    "            sergio=True,\n",
    "            saucie=False, \n",
    "            scScope=False, \n",
    "            deepImpute=False, \n",
    "            magic=False, \n",
    "            genie=False,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=False,\n",
    "            precision_recall_k=False,\n",
    "            run_with_regs=False,\n",
    "            iteration=0\n",
    "        )\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import run_scvi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_target_regs(dataset):\n",
    "    if dataset == 1:   \n",
    "        target_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Interaction_cID_4.txt'\n",
    "        regs_path = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Regs_cID_4.txt'\n",
    "    elif dataset == 2:\n",
    "        target_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Interaction_cID_5.txt'\n",
    "        regs_path = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Regs_cID_5.txt'\n",
    "    else:\n",
    "        target_file = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Interaction_cID_6.txt'\n",
    "        regs_path = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Regs_cID_6.txt'\n",
    "    return target_file, regs_path    \n",
    "\n",
    "def scvi_impute():\n",
    "    ret_df = None\n",
    "    for dataset in [1, 2, 3]:\n",
    "        save_path = f\"./zero_imputation_experiments/DS{dataset}/\"\n",
    "        y = np.load(save_path + \"/DS6_noisy.npy\")\n",
    "        target_file, regs_path = fetch_target_regs(dataset)\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            futures = []\n",
    "            for i in range(8):\n",
    "                futures.append(executor.submit(run_scvi, \n",
    "                    data=y, \n",
    "                    save_path=save_path, \n",
    "                    it=i, \n",
    "                    file_extension=f\"_iter{i}\",\n",
    "                    target_file=target_file\n",
    "                ))\n",
    "                clear_output()\n",
    "            for future in tqdm(futures):\n",
    "                vim, it = future.result()\n",
    "                res = {\n",
    "                    \"dataset\": dataset,\n",
    "                    \"method\": \"scvi\",\n",
    "                    \"roc\": vim,\n",
    "                    \"iteration\": it }\n",
    "                if ret_df is None:\n",
    "                    ret_df = pd.DataFrame(columns=res.keys())\n",
    "                new_df = pd.DataFrame([res], columns=res.keys())\n",
    "                ret_df = pd.concat([ret_df, new_df], ignore_index=True)\n",
    "                ret_df.to_csv(\"zero_imputation_experiments/scvi_imputation_results.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi_impute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn-smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import run_knn\n",
    "\n",
    "def run_smoothing():\n",
    "    ret_df = None\n",
    "    for dataset in [1,2,3]:\n",
    "        save_path = f\"./zero_imputation_experiments/DS{dataset}/\"\n",
    "        y = np.load(save_path + \"/DS6_noisy.npy\")\n",
    "        target_file, regs_path = fetch_target_regs(dataset)\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            futures = []\n",
    "            for i in range(8):\n",
    "                futures.append(executor.submit(run_knn, \n",
    "                    data=y,\n",
    "                    k=32,\n",
    "                    save_path=save_path, \n",
    "                    it=i, \n",
    "                    file_extension=f\"_iter{i}\",\n",
    "                    target_file=target_file\n",
    "                ))\n",
    "                clear_output()\n",
    "            for future in tqdm(futures):\n",
    "                vim, it = future.result()\n",
    "                res = {\n",
    "                    \"dataset\": dataset,\n",
    "                    \"method\": \"knn\",\n",
    "                    \"roc\": vim,\n",
    "                    \"iteration\": it }\n",
    "                if ret_df is None:\n",
    "                    ret_df = pd.DataFrame(columns=res.keys())\n",
    "                new_df = pd.DataFrame([res], columns=res.keys())\n",
    "                ret_df = pd.concat([ret_df, new_df], ignore_index=True)\n",
    "                ret_df.to_csv(\"zero_imputation_experiments/knn_imputation_results.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_smoothing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_smoothing\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_smoothing' is not defined"
     ]
    }
   ],
   "source": [
    "run_smoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
